{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download Drivers for SQL database connectivity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#For Linux and Mac OS:\n",
    "    \n",
    "https://docs.microsoft.com/en-us/sql/connect/odbc/linux-mac/installing-the-microsoft-odbc-driver-for-sql-server?view=sql-server-2017\n",
    "    \n",
    "    \n",
    "#For Windows:\n",
    "https://www.microsoft.com/en-us/download/details.aspx?id=56567    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PostgreSQL (No need to install Microsoft ODBC drivers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#!pip install psycopg2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Method1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#!pip install pyodbc\n",
    "#!pip install pypyodbc\n",
    "#import pyodbc\n",
    "import pypyodbc\n",
    "import psycopg2\n",
    "import csv\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "host = '**********'\n",
    "database = '***********'\n",
    "user = '***********'\n",
    "password = '***********'\n",
    "driver='{ODBC Driver 17 for SQL Server}'\n",
    "Enabled = 'Enabled'\n",
    "connection = pypyodbc.connect(\"DRIVER={ODBC Driver 17 for SQL Server};\"\n",
    "                 \"SERVER=***********;\"\n",
    "                 \"DATABASE=***********;\"\n",
    "                 \"UID=***********;\"\n",
    "                 \"PWD=***********;\"\n",
    "                  \"TrustServerCertificate=no;\"\n",
    "                 \"Connection Timeout=60\")\n",
    "\n",
    "# connection = pypyodbc.connect('Driver={ODBC Driver 17 for SQL Server};'\n",
    "#    'Server=***********;'\n",
    "#    'Database=***********;'\n",
    "#    'uid=***********;pwd=***********;'\n",
    "#    'encoding=\"utf-8\"')\n",
    "\n",
    "cursor = connection.cursor()\n",
    "# connection.setencoding(unicode, encoding='utf-8', ctype=pyodbc.SQL_CHAR)\n",
    "\n",
    "query = \"SELECT top 10 * FROM [table] with (NOLOCK)\"\n",
    "df = pd.read_sql(query,connection)\n",
    "connection.commit()\n",
    "# connection.close()\n",
    "#df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# df.columns.values\n",
    "colnames = ['log***','gfhdfxh']\n",
    "df.columns = colnames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = df.rename(columns={'dvsz':'vzs', 'hdxxh':'xhth'})\n",
    "df2 = df[['zv','vzs']]\n",
    "curr_d = tuple(set(df2['current_device']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#for uploading data to Postgres\n",
    "\n",
    "conn = psycopg2.connect(\"dbname='*****' user='beewise' host='******' password='********'\")\n",
    "cur = conn.cursor()\n",
    "# query = \"select id as user_id,current_device from users_user where current_device in \" + str(curr_d)\n",
    "query = \"select * from [table];\"\n",
    "print query\n",
    "\n",
    "dfp = pd.read_sql(query,conn)\n",
    "#conn.commit()\n",
    "# connection.close()\n",
    "print (\"\\n\")\n",
    "print (\"Query excecuted successfully\")\n",
    "\n",
    "dfp_dict = dfp.set_index('current_device').to_dict()['user_id'] #creating dictionary from two columns for mapping\n",
    "dfp_dict\n",
    "df2['user_id'] = df2['current_device'].map(dfp_dict) #inserting new column with values associate to records which are  in dictionary created from two columns of another dataframe for mapping\n",
    "\n",
    "df2 = df2.login.replace([None], 0)\n",
    "df2['user_id'] = df2['user_id'].astype('int64')\n",
    "\n",
    "\n",
    "from sqlalchemy import create_engine\n",
    "engine = create_engine('postgresql+psycopg2://user:password@hostname/database_name')\n",
    "\n",
    "df2.to_sql('table_name', con = engine, if_exists='append',index=False)\n",
    "print (\"\\nQuery excecuted successfully\")\n",
    "# connection.close()\n",
    "# engine.drop\n",
    "# -=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=--=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Method 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# postgresql connection test\n",
    "import pandas as pd\n",
    "import psycopg2\n",
    "\n",
    "conn = psycopg2.connect(\"dbname='********' user='*********' host='***********' password='*******'\")\n",
    "cur = conn.cursor()\n",
    "conn.autocommit = True\n",
    "\n",
    "query1 = \"select column_name from information_schema.columns where table_name='users_user'\"\n",
    "query = \"SELECT * FROM users_user where current_device in ('deleted','deleted_deleted_99xxxxxxxx');\" \n",
    "cur.execute(query1)\n",
    "columns = cur.fetchall()\n",
    "cur.execute(query)\n",
    "data = cur.fetchall()\n",
    "col = [str(i[0]) for i in columns]\n",
    "col\n",
    "conn.close\n",
    "#print (data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data, columns=col)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SQL Server/ MSSQL (Install Microsoft ODBC drivers first)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Method 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#!pip install pyodbc\n",
    "import pyodbc\n",
    "import pandas as pd\n",
    "\n",
    "host = '<Enter IP here>'\n",
    "database = 'Application_data'\n",
    "user = 'analysis'\n",
    "password = '<enter password>'\n",
    "driver='{ODBC Driver 17 for SQL Server}'\n",
    "Enabled = 'Enabled'\n",
    "connection = pyodbc.connect('DRIVER={};SERVER={};DATABASE={};UID={};PWD={};ColumnEncryption={};'.format('{ODBC Driver 17 for SQL Server}', host,database,user,password,Enabled))\n",
    "cursor = connection.cursor()\n",
    "query = \"SELECT top 10 * FROM table\"\n",
    "df = pd.read_sql(query,connection)\n",
    "df.head()\n",
    "\n",
    "df['event_value'] = df['event_value'].replace([None], ['{}'])\n",
    "\n",
    "#Dictionary like string records to dictionary e.g. '{'a'='abc','b'=2}' to {'a'='abc','b'=2} for each record in column\n",
    "import json\n",
    "from io import StringIO\n",
    "def str_to_dict(dict_str):\n",
    "     # Convert to proper json format\n",
    "    #dict_string = dict_str.replace(\"'\", '\"').replace(\"u'\", \"'\")\n",
    "    try:\n",
    "        return json.loads(dict_str.strip())\n",
    "    except:\n",
    "        logging.error(str(dict_str)+\"\\n\")\n",
    "        print (dict_str + \"\\n\" )\n",
    "        return {}\n",
    "            \n",
    "# logging.info(\"\\nDate: \"+str(aa)+\"\\nQuery: \"+str(query)+\"\\nExecution time: \"+str(c))\n",
    "df['event_value'] = df['event_value'].apply(str_to_dict) \n",
    "\n",
    "\n",
    "df['event_value'] = df['event_value'].apply(lambda x: {k.strip(): v for k, v in x.items()}) #stripping leading and trailing spaces from keys to avoid duplicates\n",
    "\n",
    "################# Creating multiple columns based on keys from dictionary records of one column and appending to original dataframe \n",
    "df = pd.concat([df, df['event_value'].apply(pd.Series)], axis = 1)\n",
    "############################################################################\n",
    "\n",
    "#converting all columns to String except ID\n",
    "df = df.replace([None], [''])\n",
    "cols=[i for i in df.columns if i not in [\"ID\"]]\n",
    "for col in cols:\n",
    "    df[col]=df[col].astype(str)\n",
    "    \n",
    "    \n",
    "###############SQL Alchemy for data uploading#################\n",
    "from sqlalchemy import create_engine \n",
    "import urllib\n",
    "server = '*****'\n",
    "database = '********'\n",
    "username = '**********'\n",
    "password = '*********'\n",
    "#driver='{ODBC Driver 17 for SQL Server}'\n",
    "#Enabled = 'Enabled'\n",
    "params = urllib.parse.quote_plus(\n",
    "'DRIVER={ODBC Driver 17 for SQL Server};'+ \n",
    "'SERVER='+server+';DATABASE='+database+';UID='+username+';PWD='+ password) \n",
    "\n",
    "engine = create_engine(\"mssql+pyodbc:///?odbc_connect=%s\" % params) \n",
    "\n",
    "###Connection checking\n",
    "connected = pd.io.sql._is_sqlalchemy_connectable(engine)\n",
    "logging.info(\"connected:\" + str(connected))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from datetime import timedelta\n",
    "import datetime\n",
    "a = datetime.datetime.now()\n",
    "print (a)\n",
    "\n",
    "q = \"SELECT top 10 * FROM table\"\n",
    "dfcc = pd.read_sql(q,connection)\n",
    "\n",
    "# len(dfcc.columns.values)\n",
    "dfcc.dtypes\n",
    "\n",
    "type(df.email.iloc[0])\n",
    "dfcc.columns.values\n",
    "\n",
    "new = list(set(df.columns)-set(dfcc.columns))\n",
    "print (new)\n",
    "\n",
    "#Inserting new columns (one by one) if it does not exist in SQL table\n",
    "if len(new)!=0:\n",
    "    for col in range(len(new)):\n",
    "        qq = \"ALTER TABLE Apps_Flyer_New ADD [%s] VARCHAR(max);\"%new[col]\n",
    "        print (qq)\n",
    "        cursor.execute(qq)\n",
    "        # connection.commit()\n",
    "        logging.info(\"%s New columns created viz %s\"%(str(len(new)),str(new)))\n",
    "else:\n",
    "    logging.info(\"No new columns created\")\n",
    "\n",
    "df.to_sql('Apps_Flyer_New', con=engine, if_exists='append', index=False, chunksize=20000) \n",
    "# df.to_sql('Apps_Flyer_New85', con=engine, if_exists='replace', index=False, chunksize=20000) \n",
    "\n",
    "\n",
    "b = datetime.datetime.now()\n",
    "print (b)\n",
    "\n",
    "c = b - a\n",
    "\n",
    "time = divmod(c.days * 86400 + c.seconds, 60)\n",
    "print (time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Email mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "equery = \"SELECT email_id FROM email_id_mapping\"\n",
    "dfem = pd.read_sql(equery,connection)\n",
    "dfem.head()\n",
    "\n",
    "##########  Logic 1 (Load data from SQL) Start #######################\n",
    "# equery = \"SELECT Email1,[Email ID],[Email id2],email,[email id1],emailId FROM table where CreatedDate>='2018-08-10 00:00:00.000' and CreatedDate<'2018-08-13 00:00:00.000'\"  \n",
    "equery = \"SELECT Email1,[Email ID],[Email id2],email,[email id1],emailId FROM Apps_Flyer_New\"  \n",
    "dfe = pd.read_sql(equery,connection)\n",
    "print (len(dfe))\n",
    "dfe.columns.values\n",
    "# set(df.Col1).union(set(df.Col2))\n",
    "# pd.unique(df1[['Col1', 'Col2']].values.ravel('K'))\n",
    "ue = pd.unique(dfe[['Email1', 'Email ID', 'Email id2','email', 'email id1', 'emailId']].values.ravel('K')).tolist()\n",
    "print (len(ue))\n",
    "##########  Logic 1 (Load data from SQL) end #######################\n",
    "\n",
    "\n",
    "##########  Logic 2 (Existing data frame) start #######################\n",
    "# dfcol = df.columns.values \n",
    "# colnames = ['Email1', 'Email ID', 'Email id2','email', 'emailId', 'email id1']\n",
    "# col = list(set.intersection(set(dfcol),set(colnames)))\n",
    "# col\n",
    "\n",
    "# ue = pd.unique(df[col].values.ravel('K')).tolist()\n",
    "# print (len(ue))\n",
    "##########  Logic 2 (Existing data frame) End #######################\n",
    "\n",
    "uef = pd.DataFrame({'email':ue})\n",
    "\n",
    "# udf.apply(lambda x: sum(x.isnull()))\n",
    "uef['email'].isnull().sum()\n",
    "\n",
    "# udf.replace([''],[None],inplace=True)\n",
    "# udf.dropna(subset=['mobile'], inplace=True)\n",
    "\n",
    "uef.replace([''],[None],inplace=True)\n",
    "uef.dropna(subset=['email'], inplace=True)\n",
    "\n",
    "# len(uef[uefdf.email.str.contains(\"@\") == False])\n",
    "\n",
    "#condition\n",
    "uef = uef[uef.email.str.contains(\"@\")]\n",
    "uef['email']=uef['email'].map(lambda x: x.strip())\n",
    "print (len(uef))\n",
    "\n",
    "# ll = uef['email'].tolist()\n",
    "# uel = [x for x in ll if \"@\" in x ]\n",
    "# uef = pd.DataFrame({'email':uel})\n",
    "uef = uef[uef.email.str.len()<75]\n",
    "# uel = [x.strip(' ') for x in uel]\n",
    "# ueno = [x for x in uel if \"@\" not in x ]\n",
    "# len(uel)\n",
    "\n",
    "# diffle1 = [i.lower() for i in diffle1]\n",
    "# diffle1 = [i.upper() for i in diffle1]\n",
    "# df['x'].str.lower()\n",
    "ediffl = list(set(uef.email.str.lower())-set(dfem.email_id.str.lower()))\n",
    "print (len(ediffl))\n",
    "\n",
    "edfdiff = pd.DataFrame({'email':ediffl})\n",
    "\n",
    "edfdiff.replace([''],[None],inplace=True)\n",
    "edfdiff.dropna(subset=['email'], inplace=True)\n",
    "#Conditions\n",
    "# ediffl1 = [ x for x in ediffl if \"*\" not in x ]\n",
    "# print (len(ediffl1))\n",
    "# ediffl0 = [ x for x in ediffl if \"*\" in x ]\n",
    "# print (len(ediffl0))\n",
    "edfdiff.to_sql('table', con=engine, if_exists='replace', index=False)\n",
    "\n",
    "print (\"\\n\")\n",
    "print (\"Query excecuted successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pquery = \"SELECT code FROM l_code_mapping\"\n",
    "dfpm = pd.read_sql(pquery,connection)\n",
    "dfpm.head()\n",
    "cquery = \"SELECT ID1,Id FROM table\"\n",
    "pdf = pd.read_sql(cquery,connection)\n",
    "print (len(pdf))\n",
    "pdf.columns.values\n",
    "\n",
    "# set(df.Col1).union(set(df.Col2))\n",
    "# pd.unique(df1[['Col1', 'Col2']].values.ravel('K'))\n",
    "#['PhoneNumber', 'phoneNo', 'Phone', 'Mobile', 'Phone no']\n",
    "up = pd.unique(pdf[['ID1', 'Id']].values.ravel('K')).tolist()\n",
    "print (len(up))\n",
    "\n",
    "up = [str(x) for x in up if \"@\" not in str(x)]\n",
    "up = [str(x) for x in up if \"nan\" not in str(x)]\n",
    "up = [str(x) for x in up if \"None\" not in str(x)]\n",
    "\n",
    "# udf = pd.DataFrame({'mobile':udl})\n",
    "updf = pd.DataFrame({'code':up})\n",
    "\n",
    "dfpm.columns.values\n",
    "\n",
    "updf['code'].isnull().sum()\n",
    "\n",
    "updf.replace([''],[None],inplace=True)\n",
    "updf.dropna(subset=['code'], inplace=True)\n",
    "\n",
    "# len(uef[uefdf.email.str.contains(\"@\") == False])\n",
    "\n",
    "#condition\n",
    "# uef = uef[uef.email.str.contains(\"@\")]\n",
    "updf['code']=updf['code'].map(lambda x: x.strip())\n",
    "print (len(updf))\n",
    "\n",
    "\n",
    "pdiffl = list(set(updf.code.str.upper())-set(dfpm.l_code.str.upper()))\n",
    "print (len(pdiffl))\n",
    "\n",
    "pdfdiff = pd.DataFrame({'code':pdiffl})\n",
    "\n",
    "pdfdiff.replace([''],[None],inplace=True)\n",
    "pdfdiff.dropna(subset=['code'], inplace=True)\n",
    "#Conditions\n",
    "# ediffl1 = [ x for x in ediffl if \"*\" not in x ]\n",
    "# print (len(ediffl1))\n",
    "# ediffl0 = [ x for x in ediffl if \"*\" in x ]\n",
    "# print (len(ediffl0))\n",
    "pdfdiff.to_sql('table2', con=engine, if_exists='replace', index=False)\n",
    "print (\"\\n\")\n",
    "print (\"Query excecuted successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mobile no. mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "mquery = \"SELECT mobile_no FROM mobile_no_mapping\"\n",
    "dfmm = pd.read_sql(mquery,connection)\n",
    "dfmm.head()\n",
    "\n",
    "m1query = \"SELECT PhoneNumber,phoneNo,Phone,Mobile,[Phone no] FROM table\"\n",
    "dfm = pd.read_sql(m1query,connection)\n",
    "dfm.columns.values\n",
    "\n",
    "#https://stackoverflow.com/questions/20763012/creating-a-pandas-dataframe-from-a-numpy-array-how-do-i-specify-the-index-colum\n",
    "#pd.concat([df, pd.Series(list(set(df['Ligand_miss'].values) - set(df['Ligand_hit'].values)))], ignore_index=True, axis=1)\n",
    "# diff=pd.Series(list(set(udf['mobile'].values) - set(dfm['mobile_no'].values)))\n",
    "udl = pd.unique(dfm[['PhoneNumber', 'phoneNo', 'Phone', 'Mobile', 'Phone no']].values.ravel('K')).tolist()\n",
    "print (len(udl))\n",
    "\n",
    "udl = [str(x) for x in udl if \"@\" not in str(x)]\n",
    "udl = [str(x) for x in udl if \"*\" not in str(x)]\n",
    "\n",
    "udf = pd.DataFrame({'mobile':udl})\n",
    "print (len(udf))\n",
    "\n",
    "udf.replace([''],[None],inplace=True)\n",
    "udf.dropna(subset=['mobile'], inplace=True)\n",
    "udf['mobile'] = udf['mobile'].apply(lambda x: x.replace(\" \", \"\"))\n",
    "udf['mobile'] = udf['mobile'].apply(lambda x: x.strip('.0'))\n",
    "\n",
    "print (len(udf))\n",
    "\n",
    "# aa = udf['mobile'].apply(lambda x: str(x)[-10:] if x.isdigit() else str(x))\n",
    "# aa1 = dft['Phone1'].apply(lambda x: str(x)[2:] if (x.isdigit() and len(str(x))==12) else str(x))\n",
    "# aa = udf['mobile'].apply(lambda x: str(x)[-10:])\n",
    "# aa = aa[aa.apply(lambda x: x.isdigit())]\n",
    "aa1 = udf['mobile'][udf['mobile'].apply(lambda x: x.isdigit())]\n",
    "aa = aa1.apply(lambda x: x if len(str(x))>6 else np.NaN).dropna()\n",
    "# aa = aa.astype(int)\n",
    "print (len(aa))\n",
    "\n",
    "# print (dfdiff[dfdiff.mobile.str.len() == 12])\n",
    "print (sum(aa.isnull()))\n",
    "dfm1 = aa.to_frame()\n",
    "print (dfm1.head())\n",
    "print (len(dfm1))\n",
    "\n",
    "diffl = list(set(dfm1.mobile)-set(dfmm.mobile_no))\n",
    "print (len(diffl))\n",
    "# diffl1 = [ str(x) for x in diffl if \"*\" not in str(x) ]\n",
    "# print (len(diffl1))\n",
    "# diffl0 = [ str(x) for x in diffl if \"*\" in str(x) ]\n",
    "# print (len(diffl0))\n",
    "\n",
    "# difflm = [ x for x in diffl1 if \"@\" not in x ]\n",
    "# difflm1 = [s.strip('.0') for s in difflm]\n",
    "# difflm1 = [s.replace(\" \", \"\") for s in difflm1]\n",
    "# print (len(difflm1))\n",
    "# difflm1\n",
    "\n",
    "dfdiff = pd.DataFrame({'mobile':diffl})\n",
    "\n",
    "dfdiff.replace([''],[None],inplace=True)\n",
    "dfdiff.dropna(subset=['mobile'], inplace=True)\n",
    "\n",
    "\n",
    "print (dfdiff.head())\n",
    "\n",
    "print (dfdiff.shape)\n",
    "\n",
    "dfdiff.to_sql('table2', con=engine, if_exists='replace', index=False)\n",
    "# dfdiff = dfdiff[dfdiff.mobile.apply(lambda x: x.isnumeric())]\n",
    "\n",
    "# dfdiff = diffl1.to_frame()\n",
    "# dfdiff = dfdiff.rename(columns= {0: 'mobile'})\n",
    "print (\"\\n\")\n",
    "print (\"Query excecuted successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Method 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#!pip install pyodbc\n",
    "import pyodbc\n",
    "import csv\n",
    "\n",
    "host = '<Enter IP here>'\n",
    "database = 'Application_data'\n",
    "user = 'analysis'\n",
    "password = '<enter password>'\n",
    "driver='{ODBC Driver 17 for SQL Server}'\n",
    "Enabled = 'Enabled'\n",
    "connection = pyodbc.connect('DRIVER={};SERVER={};DATABASE={};UID={};PWD={};ColumnEncryption={};'.format('{ODBC Driver 17 for SQL Server}', host,database,user,password,Enabled))\n",
    "cursor = connection.cursor()\n",
    "#query = \"SELECT top 10 * FROM CUSTOMERS\"\n",
    "#query = \"exec sp_columns CUSTOMERS\" #To get the column names\n",
    "#query = \"SELECT * FROM Sys.Tables\"\n",
    "#query = \"CREATE TABLE CUSTOMERS(ID INT NOT NULL,NAME VARCHAR (20) NOT NULL,AGE  INT NOT NULL,ADDRESS  CHAR (25) ,SALARY   DECIMAL (18, 2), PRIMARY KEY (ID))\"\n",
    "#query = \"INSERT INTO CUSTOMERS (ID,NAME,AGE,ADDRESS,SALARY) VALUES (1, 'ABC', 32, 'xyz', 100.00 );\"\n",
    "\n",
    "cursor.execute(query)        \n",
    "print (query)\n",
    "#print (row)\n",
    "#close the connection to the database.\n",
    "data = cursor.fetchall()\n",
    "print (data)\n",
    "connection.commit()\n",
    "connection.close()\n",
    "print (\"\\n\")\n",
    "print (\"Query excecuted successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Method 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pyodbc\n",
    "import csv\n",
    "\n",
    "server = '<Enter IP here>'\n",
    "database = '******'\n",
    "username = '*****'\n",
    "password = '<enter password>'\n",
    "driver='{ODBC Driver 17 for SQL Server}'\n",
    "\n",
    "connection = pyodbc.connect('DRIVER='+driver+';SERVER='+server+';PORT=1443;DATABASE='+database+';UID='+username+';PWD='+password)\n",
    "cursor = connection.cursor()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MongoDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#!pip install pymysql\n",
    "\n",
    "import pymysql\n",
    "\n",
    "pymysql.install_as_MySQLdb()\n",
    "\n",
    "import MySQLdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#!pip install pymongo\n",
    "import pymongo\n",
    "import json\n",
    "from pymongo import MongoClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Address</th>\n",
       "      <th>City</th>\n",
       "      <th>Name</th>\n",
       "      <th>State</th>\n",
       "      <th>ZIP</th>\n",
       "      <th>_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>123 Main St</td>\n",
       "      <td>Whereverville</td>\n",
       "      <td>Jane Doe</td>\n",
       "      <td>CA</td>\n",
       "      <td>90210</td>\n",
       "      <td>5af03bfa8ca570abf4a2f76c</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>555 Broadway Ave</td>\n",
       "      <td>New York</td>\n",
       "      <td>John Doe</td>\n",
       "      <td>NY</td>\n",
       "      <td>10010</td>\n",
       "      <td>5af03bfa8ca570abf4a2f76d</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Address           City      Name State    ZIP  \\\n",
       "0       123 Main St  Whereverville  Jane Doe    CA  90210   \n",
       "1  555 Broadway Ave       New York  John Doe    NY  10010   \n",
       "\n",
       "                        _id  \n",
       "0  5af03bfa8ca570abf4a2f76c  \n",
       "1  5af03bfa8ca570abf4a2f76d  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pymongo import MongoClient\n",
    "# if __name__ == '__main__':\n",
    "#     client = MongoClient(\"localhost\", 27017, maxPoolSize=50)\n",
    "client = MongoClient(\"localhost\", 27017, maxPoolSize=50)\n",
    "db = client.mydb\n",
    "collection = db.angel\n",
    "data = pd.DataFrame(list(collection.find()))\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
